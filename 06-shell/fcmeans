#!/usr/bin/python3
import time
import warnings

import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
from seaborn import scatterplot as scatter
import mpl_toolkits.mplot3d.axes3d as p3

from sklearn import cluster, datasets, mixture
from sklearn.neighbors import kneighbors_graph
from sklearn.preprocessing import StandardScaler
from itertools import cycle, islice
from fcmeans import FCM
from sklearn.base import BaseEstimator, clone
from sklearn.ensemble import RandomForestClassifier
from sklearn import metrics

#from sklearn.utils.metaestimators import if_delegate_has_method
#import os;exec(open(os.environ.get('PYTHONSTARTUP')).read())

import argparse
parser = argparse.ArgumentParser(description="")

x_algorithms = ["FCM","MeanShift","MiniBatchKMeans","SpectralClustering","DBSCAN","AffinityPropagation","Birch","GaussianMixture"]#, "AgglomerativeClustering"]

def add_param(opt2,name,value,help,required,type):
    dest='--'+name
    parser.add_argument(opt2, dest, 
                        dest=name, 
                        required=required,
                        default=value,
                        help=help,
                        metavar='',
                        type=type)
add_param('-a','affinity'     ,'nearest_neighbors','affinity'             ,False,str)
add_param('-b','eps'          ,0.3                ,'epsilon'              ,False,float)
add_param('-c','n_clusters'   ,3                  ,'numberofcluster'      ,False,int)
add_param('-d','damping'      ,0.9                ,'damping'              ,False,float)
add_param('-e','error'        ,1e-5               ,'error'                ,False,float)
add_param('-f','algorithm'    ,'fcm'              , 'algorithm'           ,False,str)
add_param('-g','plot'         ,False              ,'plot'                 ,False,bool)
add_param('-i','max_iteration',150                ,'maxiteration'         ,False,int)
add_param('-k','linkage'      ,'single'           ,'linkage'              ,False,str)
add_param('-l','labels'       ,'bin/L.csv'        ,'labelsfile'           ,False,str)
add_param('-m','fuzzification',2                  ,'degreeoffuzzification',False,float)
add_param('-n','neighbors'    ,10                 ,'neighbors'            ,False,int)
add_param('-p','preference'   ,-200               ,'preference'           ,False,int)
add_param('-q','quantile'     ,0.3                ,'quantile'             ,False,float)
add_param('-r','random_state' ,42                 ,'randomstate'          ,False,int)
add_param('-s','seed'         ,0                  ,'seed'                 ,False,int)
add_param('-u','membership'   ,'bin/U.csv'        ,'membershipfile'       ,False,str)
add_param('-v','centers'      ,'bin/V.csv'        ,'centersfile'          ,False,str)
add_param('-x','input_file'   ,'X.csv'            ,'inputfile'            ,False,str)
args = parser.parse_args()

def plot3D(labels,cluster_center,name):
    cycol = cycle('bgrcmk')
    fig   = plt.figure()
    ax    = p3.Axes3D(fig)
    for l in np.unique(labels):
          colors = next(cycol)
          ax.scatter(cluster_center[l,0], cluster_center[l,1], cluster_center[l,2], color=colors, s=100, edgecolor="k")
          ax.scatter(data[labels == l, 0]  , data[labels == l, 1]  , data[labels == l, 2]  , color=colors, s=20 , edgecolor="k")
          ax.set_xlabel("BER");ax.set_ylabel("RSSI");ax.set_zlabel("ToA")
    plt.title(name)
    plt.show()

def get_labels(algorithm, X):
    t0 = time.time()
    with warnings.catch_warnings(): # catch warnings related to kneighbors_graph
        algorithm.fit(X)
    t1 = time.time()
    
    if hasattr(algorithm, "labels_"):
          labels = algorithm.labels_.astype(np.int)
    elif hasattr(algorithm, "row_labels_"):
          labels = algorithm.row_labels_.astype(np.int)
    else:
          labels = algorithm.predict(X)
    num_clusters = len(np.unique(labels))
    if hasattr(algorithm, "cluster_centers_"):
          cluster_centerx = algorithm.cluster_centers_
    elif hasattr(algorithm, "affinity_matrix_"):
          cluster_centerx = algorithm.affinity_matrix_
    elif hasattr(algorithm, "components_"):
          cluster_centerx = algorithm.components_
    elif hasattr(algorithm, "centers"):
          cluster_centerx = algorithm.centers
    else:
        cluster_centerx=np.zeros((num_clusters,len(X[1])))
    timex=t1-t0
    return timex, algorithm, labels, cluster_centerx

data          = np.genfromtxt(args.input_file, delimiter=",", dtype="str", skip_header=1).astype(int)          # load the CSV file as a numpy matrix
bandwidth     = cluster.estimate_bandwidth(data, quantile=args.quantile)                      # estimate bandwidth for mean shift
connectivity  = kneighbors_graph(data, n_neighbors=args.neighbors, include_self=False)   # connectivity matrix for structured Ward
connectivity  = 0.5 * (connectivity + connectivity.T)                                           # make connectivity symmetric

fcm                   = FCM(n_clusters=args.n_clusters,max_iter=args.max_iteration,m=args.fuzzification,error=args.error,random_state=args.random_state)
ms                    = cluster.MeanShift(bandwidth=bandwidth, bin_seeding=True)
two_means             = cluster.MiniBatchKMeans(n_clusters=  args.n_clusters)
spectral              = cluster.SpectralClustering(n_clusters=args.n_clusters, eigen_solver="arpack", affinity=args.affinity)
dbscan                = cluster.DBSCAN(eps=args.eps)
affinity_propagation  = cluster.AffinityPropagation(damping=args.damping, preference=args.preference)
average_linkage       = cluster.AgglomerativeClustering(linkage=args.linkage, affinity=args.affinity, n_clusters=args.n_clusters, connectivity=connectivity)
birch                 = cluster.Birch(n_clusters=  args.n_clusters)
gmm                   = mixture.GaussianMixture(n_components=  args.n_clusters, covariance_type="full")

#spectralBiclustering  = bicluster.SpectralBiclustering(n_clusters=args.n_clusters, method="log", random_state=0)
#spectralCoclustering  = bicluster.SpectralCoclustering(n_clusters=args.n_clusters, random_state=0)

n_algorithms = [fcm  ,ms         ,two_means        ,spectral            ,dbscan  ,affinity_propagation ,birch  ,gmm              ]#, average_linkage]
x_algorithms = ["FCM","MeanShift","MiniBatchKMeans","SpectralClustering","DBSCAN","AffinityPropagation","Birch","GaussianMixture"]#, "AgglomerativeClustering"]

plots                 = []
names                 = []
cycol                 = cycle('bgrcmk')

for i, algorithm in enumerate(n_algorithms):
    if x_algorithms[i] == args.algorithm:
          timex, algorithm, labels_true, centers = get_labels(algorithm,data)

          df = pd.DataFrame(data=fcm.centers)
          df.to_csv(args.centers, sep=','   , header=False, float_format='%.2f', index=False) # 

    #    df = pd.DataFrame(data=fcm.u)
    #    df.to_csv(args.membership, sep=',', header=False, float_format='%.2f', index=False) # 

          df = pd.DataFrame(data=labels_true)
          df.to_csv(args.labels, sep=','    , header=False, float_format='%.2f', index=False) # 

    #
          model_affinityPropagation     = cluster.AffinityPropagation(preference=-50).fit(data)
          centers_affinityPropagation   = model_affinityPropagation.cluster_centers_indices_
          labels                        = model_affinityPropagation.labels_

          # metrics
          noise           = list(labels).count(-1)                                                                              # Estimated number of noise points: %d"
          homogeneity     = metrics.homogeneity_score         (labels_true, labels)                                              #"Homogeneity: %0.3f"
          completeness    = metrics.completeness_score        (labels_true, labels)                                               # Completeness: %0.3f"
          v_measure       = metrics.v_measure_score           (labels_true, labels)                                               # V-measure: %0.3f"
          rand_index      = metrics.adjusted_rand_score       (labels_true, labels)                                              # Adjusted Rand Index: %0.3f"
          adjusted_mutual = metrics.adjusted_mutual_info_score(labels_true, labels, average_method="arithmetic")                 # Adjusted Mutual Information: %0.3f"
          silhouette      = metrics.silhouette_score          (data, labels_true, metric="euclidean", sample_size=len(data))    # Silhouette Coefficient: %0.3f"

          print(x_algorithms[i])
          print("Time:           ", timex)
          print("noise:          ", noise)
          print("homogeneity:    ", homogeneity)
          print("completeness:   ", completeness)
          print("v_measure:      ", v_measure)
          print("rand_index:     ", rand_index)
          print("adjusted_mutual:", adjusted_mutual)
          print("silhouette:     ", silhouette)
          
          if (args.plot):
              plot3D(labels_true,centers, x_algorithms[i])



